# LanguageTranslationTransformer-LTT-
# 🧠 Custom Language Translation Transformer (English–Telugu)

This project implements a Transformer-based model from scratch. It translates sentences from **English to Telugu**, demonstrating deep understanding of sequence-to-sequence learning, self-attention mechanisms, and positional encodings.
This Model was Trained with limited resources(Google Colab GPU) for 10 epochs with 40,000 data. still the performance is good.
SOURCE: I am not a very good a student.
PREDICTED: నేను చాలా మంచి విద్యార్థిని కాదు .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 

---

## 🚀 Features

- ✅ Transformer architecture fully implemented from scratch in PyTorch
- ✅ Encoder–Decoder architecture with multi-head attention
- ✅ positional encoding
- ✅ Custom data preprocessing and batching pipeline
- ✅ Trained on parallel English–Telugu dataset
- ✅ Supports inference from both raw text or test set index
- ✅ Model export/load using `torch.save()` and `load_state_dict()`
---

